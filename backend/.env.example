# Vocalis backend configuration

# API Endpoints
LLM_API_ENDPOINT=http://127.0.0.1:1234/v1  # Place your local LLM API endpoint here (default is LM Studio). Note: do NOT include /chat/completions
LLM_API_KEY=  # Your API key (leave blank if your provider doesn't require one)
LLM_MODEL=  # Model name (leave blank if your provider only has one model)
TTS_API_ENDPOINT=http://localhost:8880/v1/audio/speech  # Place your local TTS API endpoint here (default is Orpheus-FASTAPI native python launcher) - If you're using Orpheus-FASTAPI Docker Container versus native python launcher, replace "localhost" with "127.0.0.1:5005"

# Whisper Model Configuration
WHISPER_MODEL=base  # Options: tiny.en, base.en, small.en, medium.en, large

# TTS Configuration
TTS_MODEL=kokoro
TTS_VOICE=af_bella
TTS_FORMAT=wav        # Format for TTS output (wav, mp3, opus, flac)

# Web Server Configuration
# Host/IP address to bind the web server to
# Use 0.0.0.0 to listen on all interfaces, 127.0.0.1 for localhost only, or a specific IP (e.g., Tailscale IP)
# Example: 0.0.0.0 for all interfaces, 127.0.0.1 for localhost only, 100.x.x.x for Tailscale
SERVER_HOST=0.0.0.0

# Port number for the web server (HTTP + WebSocket on same port)
# Change this if 7744 is already in use
SERVER_PORT=7744

# Audio Processing
VAD_THRESHOLD=0.1          # Voice activity detection threshold (0.0-1.0)
VAD_BUFFER_SIZE=30         # Buffer size in milliseconds
AUDIO_SAMPLE_RATE=44100    # Sample rate in Hz